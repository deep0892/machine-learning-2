{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Drug_Design_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nUpjRbUIkjK"
      },
      "source": [
        "import argparse\n",
        "import urllib\n",
        "import gzip\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDIaoEdrHOrQ"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vWO7UdLeq-w"
      },
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Dataset/MoleculeSythesis/dataset/AA.csv')\n",
        "data = data[:250000]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 824
        },
        "id": "yI68FB6-GJBf",
        "outputId": "1eb2667d-ccf0-4e72-9538-bc7ac99043c2"
      },
      "source": [
        "df1 = pd.read_csv('/content/drive/MyDrive/Dataset/MoleculeSythesis/dataset/AA.csv')\n",
        "df2 = pd.read_csv('/content/drive/MyDrive/Dataset/MoleculeSythesis/BJ.csv')\n",
        "data = pd.concat([df1, df2])\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "data = data[:250000]\n",
        "data.head(25)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>zinc_id</th>\n",
              "      <th>smiles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ZINC000117053873</td>\n",
              "      <td>C/C(=C\\CC1CCCCCCCCC1)C(=O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ZINC000038034639</td>\n",
              "      <td>Cc1noc(CNC[C@H](O)CO)n1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ZINC000213110151</td>\n",
              "      <td>N[C@H](COC[C@H](O)CO)C(=O)O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ZINC000691458499</td>\n",
              "      <td>CCCCCCCCCC1(CN)CC(C)C1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ZINC000307621149</td>\n",
              "      <td>CC(=O)N(C)CC(=O)NO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ZINC000020687759</td>\n",
              "      <td>O=C1C(=O)N(O)[C@@H]2CO[C@H]12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>ZINC000198876095</td>\n",
              "      <td>CC(C)=CC/C=C(C)\\C=C/O[Si](C)(C)C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ZINC001459398562</td>\n",
              "      <td>CC[C@H](c1ccccc1)N(CC)CCCC1CC1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ZINC001653295318</td>\n",
              "      <td>CC(C)C[C@H]1CCCN1C[C@@H](C)CC(C)(C)C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ZINC000104634531</td>\n",
              "      <td>NC(=O)C(CCO)C(N)=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>ZINC000019049577</td>\n",
              "      <td>OC[C@H]([C@@H]1CC=NN1)[C@@H]1CN1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ZINC000143882902</td>\n",
              "      <td>C[C@H](CO)O[C@H](O)[C@@H](O)CO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>ZINC000017562194</td>\n",
              "      <td>O=C1[C@H]2OC[C@@H](O)[C@H]2[C@@H]2CN12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ZINC000018637869</td>\n",
              "      <td>C[C@H]1C(=O)N2NCC(=O)[C@H]12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ZINC000024065900</td>\n",
              "      <td>O=C[C@H]1OC[C@@H]2OC=NN[C@H]12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>ZINC000714532638</td>\n",
              "      <td>CC/C=C/C[C@H](CC)c1ccc(O)c(C)c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ZINC000687001674</td>\n",
              "      <td>CC[C@H](C)[C@H](Cl)c1cccc(SC)c1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>ZINC001190570846</td>\n",
              "      <td>CCCCCN(CCC)[C@@H]1CCc2ccccc21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>ZINC000017609664</td>\n",
              "      <td>O=C1NC[C@@H]2[C@H](O)[C@@H]2N2C[C@@H]12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>ZINC000135669355</td>\n",
              "      <td>CCCCCCC[C@](C)(CNC(C)C)C1CC1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>ZINC000199434108</td>\n",
              "      <td>NCCCC[C@H](CN)[C@H](N)CN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>ZINC000059313542</td>\n",
              "      <td>C[C@H](Cc1ccc(Cl)cc1)c1ccccc1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>ZINC000022940199</td>\n",
              "      <td>CN1C=N[C@@H]2CN[C@@H]2CN1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>ZINC000526902668</td>\n",
              "      <td>CC(=O)CC[S@@](=O)CC(=O)NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>ZINC000113878886</td>\n",
              "      <td>NC(=O)CC[C@@H](N)S(=O)(=O)O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             zinc_id                                   smiles\n",
              "0   ZINC000117053873              C/C(=C\\CC1CCCCCCCCC1)C(=O)O\n",
              "1   ZINC000038034639                  Cc1noc(CNC[C@H](O)CO)n1\n",
              "2   ZINC000213110151              N[C@H](COC[C@H](O)CO)C(=O)O\n",
              "3   ZINC000691458499                   CCCCCCCCCC1(CN)CC(C)C1\n",
              "4   ZINC000307621149                       CC(=O)N(C)CC(=O)NO\n",
              "5   ZINC000020687759            O=C1C(=O)N(O)[C@@H]2CO[C@H]12\n",
              "6   ZINC000198876095         CC(C)=CC/C=C(C)\\C=C/O[Si](C)(C)C\n",
              "7   ZINC001459398562           CC[C@H](c1ccccc1)N(CC)CCCC1CC1\n",
              "8   ZINC001653295318     CC(C)C[C@H]1CCCN1C[C@@H](C)CC(C)(C)C\n",
              "9   ZINC000104634531                       NC(=O)C(CCO)C(N)=O\n",
              "10  ZINC000019049577         OC[C@H]([C@@H]1CC=NN1)[C@@H]1CN1\n",
              "11  ZINC000143882902           C[C@H](CO)O[C@H](O)[C@@H](O)CO\n",
              "12  ZINC000017562194   O=C1[C@H]2OC[C@@H](O)[C@H]2[C@@H]2CN12\n",
              "13  ZINC000018637869             C[C@H]1C(=O)N2NCC(=O)[C@H]12\n",
              "14  ZINC000024065900           O=C[C@H]1OC[C@@H]2OC=NN[C@H]12\n",
              "15  ZINC000714532638          CC/C=C/C[C@H](CC)c1ccc(O)c(C)c1\n",
              "16  ZINC000687001674          CC[C@H](C)[C@H](Cl)c1cccc(SC)c1\n",
              "17  ZINC001190570846            CCCCCN(CCC)[C@@H]1CCc2ccccc21\n",
              "18  ZINC000017609664  O=C1NC[C@@H]2[C@H](O)[C@@H]2N2C[C@@H]12\n",
              "19  ZINC000135669355             CCCCCCC[C@](C)(CNC(C)C)C1CC1\n",
              "20  ZINC000199434108                 NCCCC[C@H](CN)[C@H](N)CN\n",
              "21  ZINC000059313542            C[C@H](Cc1ccc(Cl)cc1)c1ccccc1\n",
              "22  ZINC000022940199                CN1C=N[C@@H]2CN[C@@H]2CN1\n",
              "23  ZINC000526902668                CC(=O)CC[S@@](=O)CC(=O)NN\n",
              "24  ZINC000113878886              NC(=O)CC[C@@H](N)S(=O)(=O)O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox-GDOPdtBW8",
        "outputId": "ac29c8f8-901e-492e-ba71-6e1fc95df4cc"
      },
      "source": [
        "data['smiles'].apply(len).max()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPPLH98PIUPJ",
        "outputId": "2a9eef23-c702-4d0c-a8a2-d63c087c4b7e"
      },
      "source": [
        "smiles_data = data['smiles'][:250000]\n",
        "smiles_data = np.array(smiles_data).reshape(-1)\n",
        "print('Number of mols: '+str(len(smiles_data)))\n",
        "idx = [i for i, x in enumerate(smiles_data) if len(x)<=120]\n",
        "print('Number of valid mols: '+str(len(idx)))\n",
        "smiles_data = smiles_data[idx]\n",
        "print('Getting a unique character set...')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mols: 250000\n",
            "Number of valid mols: 250000\n",
            "Getting a unique character set...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwtGUpnHIv6l",
        "outputId": "d48eeca3-1246-449b-dec4-f16d140ce68f"
      },
      "source": [
        "char_set = set()\n",
        "for i in tqdm(range(len(smiles_data))):\n",
        "    smiles_data[i] = smiles_data[i].ljust(62)\n",
        "    char_set = char_set.union(set(smiles_data[i]))\n",
        "char_set_list = sorted(list(char_set))\n",
        "print('Number of characters: '+str(len(char_set_list)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:00<00:00, 387194.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of characters: 37\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mb4hxktHI9W5",
        "outputId": "bdaf6c5b-9e60-4f4c-d3b1-5f68dc394a2c"
      },
      "source": [
        "len(char_set_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "7ZBw5c2uKN0J",
        "outputId": "2b56e380-cb21-4259-c0e5-87aca156ce73"
      },
      "source": [
        "fig, axes = plt.subplots(nrows = 1, ncols = 3, figsize = (15, 5))\n",
        "axes[0].set_title(\"SMILES length distribution\")\n",
        "axes[0].hist(data['smiles'].str.len(), align = 'left')\n",
        "axes[1].set_title(\"SMILES length less or equal than 60 distribution\")\n",
        "axes[1].hist(data[data['smiles'].str.len() <= 60]['smiles'].str.len(), align = 'left')\n",
        "axes[2].set_title(\"SMILES length greater than 60 distribution\")\n",
        "axes[2].hist(data[data['smiles'].str.len() > 60]['smiles'].str.len(), align = 'left')\n",
        "fig.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAf0ySkCK8P4",
        "outputId": "bec111e4-6a37-4956-a483-eb8405da4ba0"
      },
      "source": [
        "print(\"SMILES max length: {0}\".format(data['smiles'].str.len().max()))\n",
        "print(\"SMILES min length: {0}\".format(data['smiles'].str.len().min()))\n",
        "print(\"Number of SMILES with length less or equal than 60: {0}\".format(len(data[data['smiles'].str.len() <= 60])))\n",
        "print(\"Number of SMILES with length grather than 60: {0}\".format(len(data[data['smiles'].str.len() > 60])))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SMILES max length: 80\n",
            "SMILES min length: 4\n",
            "Number of SMILES with length less or equal than 60: 249809\n",
            "Number of SMILES with length grather than 60: 191\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBc7b-tLLdM8",
        "outputId": "0f5218e2-97d7-4ddb-917a-94a2d0550e40"
      },
      "source": [
        "# Charset Sanity Check\n",
        "charset = []\n",
        "for smile in tqdm(data['smiles'], total = len(data['smiles'])):\n",
        "    for c in smile:\n",
        "        if c not in charset:\n",
        "            charset.append(c)\n",
        "\n",
        "isbreak = False\n",
        "for l in char_set_list:\n",
        "    if l not in charset:\n",
        "        isbreak = True\n",
        "        break\n",
        "\n",
        "if not isbreak:\n",
        "    print(\"The vocabulary CHARSET contain all needed characters.\")\n",
        "else:\n",
        "    print(\"The vocabulary CHARSET does not contain all needed characters.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 162656.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The vocabulary CHARSET does not contain all needed characters.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX059rjwMwQL",
        "outputId": "adced67f-405c-4bce-e5a0-a151cd79d76f"
      },
      "source": [
        "encoder_dict =   dict((c,i) for i,c in enumerate(charset))\n",
        "decoder_dict =   dict((i,c) for i,c in enumerate(charset))\n",
        "\n",
        "def one_hot_encoder(smiles, length = 78):\n",
        "  X = np.zeros((length, len(charset)))\n",
        "  for i, c in enumerate( smiles ):\n",
        "    X[i, encoder_dict[c]] = 1\n",
        "    return X\n",
        "\n",
        "def one_hot_decoder(X):\n",
        "  smi = ''\n",
        "  X = X.argmax( axis=-1 )\n",
        "  for i in X:\n",
        "    smi += decoder_dict[i]\n",
        "  return smi\n",
        "print(encoder_dict)\n",
        "print(decoder_dict)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0, '/': 1, '(': 2, '=': 3, '\\\\': 4, '1': 5, ')': 6, 'O': 7, 'c': 8, 'n': 9, 'o': 10, 'N': 11, '[': 12, '@': 13, 'H': 14, ']': 15, '2': 16, 'S': 17, 'i': 18, 'l': 19, 'F': 20, '3': 21, '+': 22, '-': 23, 's': 24, '#': 25, 'P': 26, 'B': 27, '4': 28, 'r': 29, 'p': 30, '5': 31, '8': 32, '7': 33, '6': 34, 'I': 35}\n",
            "{0: 'C', 1: '/', 2: '(', 3: '=', 4: '\\\\', 5: '1', 6: ')', 7: 'O', 8: 'c', 9: 'n', 10: 'o', 11: 'N', 12: '[', 13: '@', 14: 'H', 15: ']', 16: '2', 17: 'S', 18: 'i', 19: 'l', 20: 'F', 21: '3', 22: '+', 23: '-', 24: 's', 25: '#', 26: 'P', 27: 'B', 28: '4', 29: 'r', 30: 'p', 31: '5', 32: '8', 33: '7', 34: '6', 35: 'I'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axzFGl-EM7rT",
        "outputId": "21998e87-6915-4f33-ada2-d493f8aefafc"
      },
      "source": [
        "x_train_encoded = []\n",
        "x_train_decoded = []\n",
        "for item in data['smiles']:\n",
        "  x_train_encoded.append(one_hot_encoder(item))\n",
        "for item in x_train_encoded:\n",
        "  x_train_decoded.append(one_hot_decoder(item))\n",
        "x_train_encoded = np.array(x_train_encoded)\n",
        "# x_train_decoded = np.array(x_train_decoded)\n",
        "print(x_train_encoded.shape)\n",
        "# print(x_train_decoded.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(250000, 78, 36)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5QVuTpMO8rP",
        "outputId": "4b1d6898-8188-448c-b128-208ba7b4e393"
      },
      "source": [
        "x_train_encoded = x_train_encoded.reshape(-1,78,36,1)\n",
        "x_train_encoded.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250000, 78, 36, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz8Mje5L0UI7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.patches as mpatches \n",
        "%matplotlib inline\n",
        "from scipy.stats import norm \n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Model \n",
        "from keras import metrics\n",
        "from keras import backend as K \n",
        "K.clear_session()\n",
        "np.random.seed(237)\n",
        "import scipy.stats as st\n",
        "import tensorflow.compat.v1.keras.backend as K \n",
        "import tensorflow as tf \n",
        "tf.compat.v1.disable_eager_execution()\n",
        "from tensorflow.keras.optimizers import Adam \n",
        "import warnings \n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "import numpy as np\n",
        "from scipy.stats import multivariate_normal"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1srg2CXj5Xv"
      },
      "source": [
        "def sampling(args):\n",
        "  z_mu, z_log_sigma = args\n",
        "  epsilon = K.random_normal(shape=(K.shape(z_mu)[0], latent_dim),\n",
        "  mean=0., stddev=1.)\n",
        "  return z_mu + K.exp(z_log_sigma) * epsilon"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5FoBrgeF5ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1525eb7b-dfbb-4d56-a4c3-93ddbec67417"
      },
      "source": [
        "img_shape = (78, 36, 1)\n",
        "batch_size = 64\n",
        "latent_dim = 2\n",
        "input_img = tf.keras.Input(shape=img_shape)\n",
        "\n",
        "# x = layers.Conv1D(16, 7,\n",
        "#                   strides = 1)(input_img)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "\n",
        "x = layers.Conv1D(32, 7,\n",
        "                  strides = 1)(input_img)\n",
        "x = layers.BatchNormalization(momentum = 0.5)(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "x = layers.Conv1D(64, 7,\n",
        "                  strides = 1)(x)\n",
        "x = layers.BatchNormalization(momentum = 0.5)(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "x = layers.Conv1D(128, 7,\n",
        "                  \n",
        "                  strides = 1)(x)\n",
        "x = layers.BatchNormalization(momentum = 0.5)(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "# x = layers.Dense(512)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "\n",
        "# x = layers.Dense(1024)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "\n",
        "\n",
        "shape_before_flattening = K.int_shape(x)\n",
        "x = layers.Flatten()(x)\n",
        "z_mu = layers.Dense(latent_dim)(x)\n",
        "z_log_sigma = layers.Dense(latent_dim)(x)\n",
        "z = layers.Lambda(sampling)([z_mu, z_log_sigma])\n",
        "\n",
        "encoder = tf.keras.Model(input_img,[z_mu,z_log_sigma])\n",
        "encoder.summary()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 78, 36, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 78, 30, 32)   256         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 78, 30, 32)   128         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 78, 30, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 78, 24, 64)   14400       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 78, 24, 64)   256         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 78, 24, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 78, 18, 128)  57472       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 78, 18, 128)  512         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 78, 18, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 179712)       0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 2)            359426      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 2)            359426      flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 791,876\n",
            "Trainable params: 791,428\n",
            "Non-trainable params: 448\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWd_wh6bTzr9"
      },
      "source": [
        "decoder_input = layers.Input(K.int_shape(z)[1:])\n",
        "x = layers.Dense(np.prod(shape_before_flattening[1:]),activation='relu')(decoder_input)\n",
        "#Decoder\n",
        "x = layers.Dense(512)(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "# x = layers.Activation('relu')(x)\n",
        "x = layers.LeakyReLU(alpha=0.3)(x)\n",
        "\n",
        "x = layers.RepeatVector(78)(x)\n",
        "\n",
        "x = tf.compat.v1.keras.layers.CuDNNGRU(512, return_sequences=True)(x)\n",
        "x = layers.BatchNormalization(momentum = 0.9)(x)\n",
        "\n",
        "# x = tf.compat.v1.keras.layers.CuDNNGRU(512, return_sequences=True)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "\n",
        "# x = tf.compat.v1.keras.layers.CuDNNGRU(512, return_sequences=True)(x)\n",
        "# x = layers.BatchNormalization()(x)\n",
        "\n",
        "x = tf.compat.v1.keras.layers.CuDNNGRU(512, return_sequences=True)(x)\n",
        "\n",
        "outputs_logits = layers.TimeDistributed(layers.Dense(36))(x)\n",
        "x = layers.Activation('tanh')(outputs_logits)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPzbwjioWZ0W"
      },
      "source": [
        "decoder = Model(decoder_input, x)\n",
        "z_decoded = decoder(z)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igEQ9jVxeprE",
        "outputId": "fa3f4380-e686-4da3-eaf3-63331d41b2ff"
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 179712)            539136    \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 512)               92013056  \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "repeat_vector_2 (RepeatVecto (None, 78, 512)           0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_4 (CuDNNGRU)       (None, 78, 512)           1575936   \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 78, 512)           2048      \n",
            "_________________________________________________________________\n",
            "cu_dnngru_5 (CuDNNGRU)       (None, 78, 512)           1575936   \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 78, 36)            18468     \n",
            "_________________________________________________________________\n",
            "activation_9 (Activation)    (None, 78, 36)            0         \n",
            "=================================================================\n",
            "Total params: 95,726,628\n",
            "Trainable params: 95,724,580\n",
            "Non-trainable params: 2,048\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8-s3hMF8qEC"
      },
      "source": [
        "class CustomVariationalLayer(keras.layers.Layer):\n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        xent_loss = keras.metrics.binary_crossentropy(x, z_decoded) #Recin loss\n",
        "        kl_loss = -5e-4 * K.mean(1 + z_log_sigma - K.square(z_mu) - K.exp(z_log_sigma), axis=-1) #KL loss\n",
        "        return K.mean(xent_loss + kl_loss)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return x\n",
        "\n",
        "y = CustomVariationalLayer()([input_img, z_decoded])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3Wm2AvY9MGf",
        "outputId": "625c6a74-d77f-4e51-d55c-71beb0f6b9b3"
      },
      "source": [
        "# VAE model statement\n",
        "vae = Model(input_img, y)\n",
        "vae.compile(optimizer='rmsprop', loss=None)\n",
        "vae.summary()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Output custom_variational_layer_2 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_2.\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 78, 36, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 78, 30, 32)   256         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 78, 30, 32)   128         conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 78, 30, 32)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 78, 24, 64)   14400       leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 78, 24, 64)   256         conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 78, 24, 64)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_6 (Conv1D)               (None, 78, 18, 128)  57472       leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 78, 18, 128)  512         conv1d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 78, 18, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 179712)       0           leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 2)            359426      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 2)            359426      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 2)            0           dense_10[0][0]                   \n",
            "                                                                 dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "model_6 (Functional)            (None, 78, 36)       95726628    lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_2 (Cus (None, 78, 36, 1)    0           input_6[0][0]                    \n",
            "                                                                 model_6[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 96,518,504\n",
            "Trainable params: 96,516,008\n",
            "Non-trainable params: 2,496\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5veujgFA9UtU",
        "outputId": "91e91aea-0888-4a9e-c5e1-9e341bb933d5"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "vae.fit(x = x_train_encoded[:20000], y=None,\n",
        "        shuffle=True,\n",
        "        epochs=20,\n",
        "        batch_size=16,callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples\n",
            "Epoch 1/20\n",
            "20000/20000 [==============================] - 47s 2ms/sample - loss: 29953058739123.5938\n",
            "Epoch 2/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 513816.9644\n",
            "Epoch 3/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 3757464982.8651\n",
            "Epoch 4/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 551.6626\n",
            "Epoch 5/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 74533595709356976.0000\n",
            "Epoch 6/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 11535052078423.0762\n",
            "Epoch 7/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 48306344956552784.0000\n",
            "Epoch 8/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 124201858769.8021\n",
            "Epoch 9/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 32678621065.5142\n",
            "Epoch 10/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 6526344918.3666\n",
            "Epoch 11/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 20.9899\n",
            "Epoch 12/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 24.1371\n",
            "Epoch 13/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 2204589619743.5342\n",
            "Epoch 14/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 5870488819761699725770752.0000\n",
            "Epoch 15/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 924283221032564817920.0000\n",
            "Epoch 16/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 26938769834129348538400768.0000\n",
            "Epoch 17/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 863479481248489275392.0000\n",
            "Epoch 18/20\n",
            "20000/20000 [==============================] - 40s 2ms/sample - loss: 1130896777181854720.0000\n",
            "Epoch 19/20\n",
            " 8112/20000 [===========>..................] - ETA: 23s - loss: 366523244747564907495424.0000"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzs06iOX9qI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "16384860-9b75-436f-d203-2a015bc4478a"
      },
      "source": [
        "sample_vector = np.array([[0,5]])\n",
        "result = decoder.predict(sample_vector)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f3f62268915b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "ywyEdpBgDUhJ",
        "outputId": "ae3955f2-263b-43fd-c207-164f40ebc9db"
      },
      "source": [
        "result.shape"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-4a99d8abe300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIOIn2hrDf_l"
      },
      "source": [
        "result = result[0].reshape(78, 36)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gc-fneGLDwIH"
      },
      "source": [
        "result.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfNi41ZYD5Pw"
      },
      "source": [
        "one_hot_decoder(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53zgDxuXE8mL"
      },
      "source": [
        "def get_loss(distribution_mean, distribution_variance):\n",
        "    \n",
        "    def get_reconstruction_loss(y_true, y_pred):\n",
        "        reconstruction_loss = tf.keras.losses.mse(y_true, y_pred)\n",
        "        reconstruction_loss_batch = tf.reduce_mean(reconstruction_loss)\n",
        "        return reconstruction_loss_batch*28*28\n",
        "    \n",
        "    def get_kl_loss(distribution_mean, distribution_variance):\n",
        "        kl_loss = 1 + distribution_variance - tf.square(distribution_mean) - tf.exp(distribution_variance)\n",
        "        kl_loss_batch = tf.reduce_mean(kl_loss)\n",
        "        return kl_loss_batch*(-0.5)\n",
        "    \n",
        "    def total_loss(y_true, y_pred):\n",
        "        reconstruction_loss_batch = get_reconstruction_loss(y_true, y_pred)\n",
        "        kl_loss_batch = get_kl_loss(distribution_mean, distribution_variance)\n",
        "        return reconstruction_loss_batch + kl_loss_batch\n",
        "    \n",
        "    return total_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gigEsCNmsl9G",
        "outputId": "15dda90a-772f-4302-efa6-5b23d43d1bd3"
      },
      "source": [
        "vae.compile(loss=get_loss(z_mu, z_log_sigma), optimizer='adam')\n",
        "vae.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 60, 36, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d (Conv1D)                 (None, 60, 30, 32)   256         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 60, 30, 32)   128         conv1d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 60, 30, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 60, 24, 64)   14400       activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 60, 24, 64)   256         conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 60, 24, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 60, 18, 128)  57472       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 60, 18, 128)  512         conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 60, 18, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 60, 18, 512)  66048       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 60, 18, 512)  2048        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 60, 18, 512)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 552960)       0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 2)            1105922     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            1105922     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 2)            0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Functional)            (None, 60, 36)       289527332   lambda[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "custom_variational_layer_3 (Cus (None, 60, 36, 1)    0           input_1[0][0]                    \n",
            "                                                                 model_3[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 291,880,296\n",
            "Trainable params: 291,875,752\n",
            "Non-trainable params: 4,544\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3184Ajmds5yT",
        "outputId": "b4996f3c-5422-40dd-acf6-6d888cbffb54"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)\n",
        "vae.fit(x = x_train_encoded[:20000], y=None,\n",
        "        shuffle=True,\n",
        "        epochs=20,\n",
        "        batch_size=200,callbacks=[callback]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples\n",
            "Epoch 1/20\n",
            "20000/20000 [==============================] - 22s 1ms/sample - loss: nan\n",
            "Epoch 2/20\n",
            "20000/20000 [==============================] - 16s 796us/sample - loss: nan\n",
            "Epoch 3/20\n",
            "20000/20000 [==============================] - 16s 793us/sample - loss: nan\n",
            "Epoch 4/20\n",
            "20000/20000 [==============================] - 16s 798us/sample - loss: nan\n",
            "Epoch 5/20\n",
            "20000/20000 [==============================] - 16s 795us/sample - loss: nan\n",
            "Epoch 6/20\n",
            "20000/20000 [==============================] - 16s 795us/sample - loss: nan\n",
            "Epoch 7/20\n",
            "20000/20000 [==============================] - 16s 794us/sample - loss: nan\n",
            "Epoch 8/20\n",
            "20000/20000 [==============================] - 16s 795us/sample - loss: nan\n",
            "Epoch 9/20\n",
            "20000/20000 [==============================] - 16s 793us/sample - loss: nan\n",
            "Epoch 10/20\n",
            "20000/20000 [==============================] - 16s 794us/sample - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f31a44c42e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zB9VSBK5tQeo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i8eWL024w8T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}